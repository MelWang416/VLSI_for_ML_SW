{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "agreed-korean",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (layer1): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n",
      "[Parameter containing:\n",
      "tensor([[0.5764, 0.2576]], requires_grad=True), Parameter containing:\n",
      "tensor([0.6773], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "### Training with manually updating W with \"Backward\" ###\n",
    "\n",
    "import torch\n",
    "#from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = [(1.0,2.1,3.0), (2.0, 3.5, 6.0), (3.0, 3.0, 9.0), (4.0, 2.1, 12.0), (5.0, 7.2, 15.0), (6.0, 10.1, 18.0)]\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.layer1 = nn.Linear(2, 1, bias = True)\n",
    "    def forward(self, x):\n",
    "        y = self.layer1(x)\n",
    "        return y\n",
    "\n",
    "net = Net()\n",
    "\n",
    "print(net)\n",
    "print(list(net.parameters()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d6cb193-c837-4cc5-9d67-a3f0f136a1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Loss 1.2279404401779175\n",
      "Epoch 0 - Loss 0.7298716902732849\n",
      "Epoch 0 - Loss 0.2539484202861786\n",
      "Epoch 0 - Loss 0.06081210449337959\n",
      "Epoch 0 - Loss 2.800746202468872\n",
      "Epoch 0 - Loss 0.19413290917873383\n",
      "Epoch 1 - Loss 1.0438872575759888\n",
      "Epoch 1 - Loss 0.6808135509490967\n",
      "Epoch 1 - Loss 0.2816847264766693\n",
      "Epoch 1 - Loss 0.08479058742523193\n",
      "Epoch 1 - Loss 2.403757333755493\n",
      "Epoch 1 - Loss 0.12639600038528442\n",
      "Epoch 2 - Loss 0.9555895924568176\n",
      "Epoch 2 - Loss 0.671552836894989\n",
      "Epoch 2 - Loss 0.29334941506385803\n",
      "Epoch 2 - Loss 0.08999153226613998\n",
      "Epoch 2 - Loss 2.1204729080200195\n",
      "Epoch 2 - Loss 0.09382972121238708\n",
      "Epoch 3 - Loss 0.8618620038032532\n",
      "Epoch 3 - Loss 0.6299751996994019\n",
      "Epoch 3 - Loss 0.279951274394989\n",
      "Epoch 3 - Loss 0.08472395688295364\n",
      "Epoch 3 - Loss 1.8580677509307861\n",
      "Epoch 3 - Loss 0.07515659928321838\n",
      "Epoch 4 - Loss 0.7682650089263916\n",
      "Epoch 4 - Loss 0.5706337690353394\n",
      "Epoch 4 - Loss 0.25332117080688477\n",
      "Epoch 4 - Loss 0.0747951865196228\n",
      "Epoch 4 - Loss 1.6249990463256836\n",
      "Epoch 4 - Loss 0.06390494108200073\n",
      "Epoch 5 - Loss 0.6803104281425476\n",
      "Epoch 5 - Loss 0.506333589553833\n",
      "Epoch 5 - Loss 0.22261039912700653\n",
      "Epoch 5 - Loss 0.06398259103298187\n",
      "Epoch 5 - Loss 1.4232714176177979\n",
      "Epoch 5 - Loss 0.05651465803384781\n",
      "Epoch 6 - Loss 0.6006613373756409\n",
      "Epoch 6 - Loss 0.44467124342918396\n",
      "Epoch 6 - Loss 0.19305115938186646\n",
      "Epoch 6 - Loss 0.05415477976202965\n",
      "Epoch 6 - Loss 1.250348448753357\n",
      "Epoch 6 - Loss 0.05102334916591644\n",
      "Epoch 7 - Loss 0.5300321578979492\n",
      "Epoch 7 - Loss 0.38916367292404175\n",
      "Epoch 7 - Loss 0.1669117510318756\n",
      "Epoch 7 - Loss 0.04592946171760559\n",
      "Epoch 7 - Loss 1.1020578145980835\n",
      "Epoch 7 - Loss 0.04640485346317291\n",
      "Epoch 8 - Loss 0.4680432677268982\n",
      "Epoch 8 - Loss 0.34078550338745117\n",
      "Epoch 8 - Loss 0.1447133719921112\n",
      "Epoch 8 - Loss 0.03928673267364502\n",
      "Epoch 8 - Loss 0.9741586446762085\n",
      "Epoch 8 - Loss 0.04218151792883873\n",
      "Epoch 9 - Loss 0.4138217866420746\n",
      "Epoch 9 - Loss 0.2991922199726105\n",
      "Epoch 9 - Loss 0.12614049017429352\n",
      "Epoch 9 - Loss 0.033963482826948166\n",
      "Epoch 9 - Loss 0.8629859089851379\n",
      "Epoch 9 - Loss 0.0381760336458683\n",
      "Epoch 10 - Loss 0.36636579036712646\n",
      "Epoch 10 - Loss 0.26351305842399597\n",
      "Epoch 10 - Loss 0.11059524118900299\n",
      "Epoch 10 - Loss 0.029656194150447845\n",
      "Epoch 10 - Loss 0.7656199932098389\n",
      "Epoch 10 - Loss 0.034363262355327606\n",
      "Epoch 11 - Loss 0.3247186541557312\n",
      "Epoch 11 - Loss 0.2327759563922882\n",
      "Epoch 11 - Loss 0.09745905548334122\n",
      "Epoch 11 - Loss 0.026101035997271538\n",
      "Epoch 11 - Loss 0.6798129677772522\n",
      "Epoch 11 - Loss 0.03077578917145729\n",
      "Epoch 12 - Loss 0.2880471646785736\n",
      "Epoch 12 - Loss 0.2061038762331009\n",
      "Epoch 12 - Loss 0.08621221035718918\n",
      "Epoch 12 - Loss 0.023098042234778404\n",
      "Epoch 12 - Loss 0.603860080242157\n",
      "Epoch 12 - Loss 0.027452999725937843\n",
      "Epoch 13 - Loss 0.2556576132774353\n",
      "Epoch 13 - Loss 0.1827821433544159\n",
      "Epoch 13 - Loss 0.07645580172538757\n",
      "Epoch 13 - Loss 0.020508402958512306\n",
      "Epoch 13 - Loss 0.5364487767219543\n",
      "Epoch 13 - Loss 0.024420619010925293\n",
      "Epoch 14 - Loss 0.22698231041431427\n",
      "Epoch 14 - Loss 0.162260964512825\n",
      "Epoch 14 - Loss 0.06790295988321304\n",
      "Epoch 14 - Loss 0.01823948509991169\n",
      "Epoch 14 - Loss 0.47653117775917053\n",
      "Epoch 14 - Loss 0.02168401889503002\n",
      "Epoch 15 - Loss 0.20155271887779236\n",
      "Epoch 15 - Loss 0.1441182792186737\n",
      "Epoch 15 - Loss 0.06034781411290169\n",
      "Epoch 15 - Loss 0.016229890286922455\n",
      "Epoch 15 - Loss 0.4232437014579773\n",
      "Epoch 15 - Loss 0.019236236810684204\n",
      "Epoch 16 - Loss 0.1789768934249878\n",
      "Epoch 16 - Loss 0.12802493572235107\n",
      "Epoch 16 - Loss 0.05364067852497101\n",
      "Epoch 16 - Loss 0.014440055005252361\n",
      "Epoch 16 - Loss 0.37585777044296265\n",
      "Epoch 16 - Loss 0.0170588456094265\n",
      "Epoch 17 - Loss 0.15892480313777924\n",
      "Epoch 17 - Loss 0.11372613906860352\n",
      "Epoch 17 - Loss 0.047672320157289505\n",
      "Epoch 17 - Loss 0.012841718271374702\n",
      "Epoch 17 - Loss 0.3337324857711792\n",
      "Epoch 17 - Loss 0.015127393417060375\n",
      "Epoch 18 - Loss 0.14111196994781494\n",
      "Epoch 18 - Loss 0.10101354122161865\n",
      "Epoch 18 - Loss 0.04235798120498657\n",
      "Epoch 18 - Loss 0.011414813809096813\n",
      "Epoch 18 - Loss 0.2962978780269623\n",
      "Epoch 18 - Loss 0.013417349196970463\n",
      "Epoch 19 - Loss 0.1252870261669159\n",
      "Epoch 19 - Loss 0.0897073820233345\n",
      "Epoch 19 - Loss 0.037624623626470566\n",
      "Epoch 19 - Loss 0.010141142643988132\n",
      "Epoch 19 - Loss 0.26304328441619873\n",
      "Epoch 19 - Loss 0.01190413348376751\n",
      "Epoch 20 - Loss 0.11123014241456985\n",
      "Epoch 20 - Loss 0.07965344935655594\n",
      "Epoch 20 - Loss 0.03341176360845566\n",
      "Epoch 20 - Loss 0.009006034582853317\n",
      "Epoch 20 - Loss 0.23351456224918365\n",
      "Epoch 20 - Loss 0.01056321058422327\n",
      "Epoch 21 - Loss 0.09874856472015381\n",
      "Epoch 21 - Loss 0.07072240859270096\n",
      "Epoch 21 - Loss 0.02966703474521637\n",
      "Epoch 21 - Loss 0.007996675558388233\n",
      "Epoch 21 - Loss 0.20729491114616394\n",
      "Epoch 21 - Loss 0.0093750124797225\n",
      "Epoch 22 - Loss 0.0876644179224968\n",
      "Epoch 22 - Loss 0.06278690695762634\n",
      "Epoch 22 - Loss 0.026337919756770134\n",
      "Epoch 22 - Loss 0.007098780944943428\n",
      "Epoch 22 - Loss 0.1840188205242157\n",
      "Epoch 22 - Loss 0.008322288282215595\n",
      "Epoch 23 - Loss 0.07782240211963654\n",
      "Epoch 23 - Loss 0.055737223476171494\n",
      "Epoch 23 - Loss 0.023380372673273087\n",
      "Epoch 23 - Loss 0.006301190238445997\n",
      "Epoch 23 - Loss 0.16335727274417877\n",
      "Epoch 23 - Loss 0.007388204801827669\n",
      "Epoch 24 - Loss 0.0690855085849762\n",
      "Epoch 24 - Loss 0.049478814005851746\n",
      "Epoch 24 - Loss 0.02075442112982273\n",
      "Epoch 24 - Loss 0.005593116395175457\n",
      "Epoch 24 - Loss 0.14501535892486572\n",
      "Epoch 24 - Loss 0.006558735854923725\n",
      "Epoch 25 - Loss 0.06132988631725311\n",
      "Epoch 25 - Loss 0.04392395168542862\n",
      "Epoch 25 - Loss 0.01842387020587921\n",
      "Epoch 25 - Loss 0.0049650599248707294\n",
      "Epoch 25 - Loss 0.12873533368110657\n",
      "Epoch 25 - Loss 0.005822512321174145\n",
      "Epoch 26 - Loss 0.05444500967860222\n",
      "Epoch 26 - Loss 0.03899315744638443\n",
      "Epoch 26 - Loss 0.016355270519852638\n",
      "Epoch 26 - Loss 0.004407257307320833\n",
      "Epoch 26 - Loss 0.11428224295377731\n",
      "Epoch 26 - Loss 0.005168977193534374\n",
      "Epoch 27 - Loss 0.048333000391721725\n",
      "Epoch 27 - Loss 0.03461528941988945\n",
      "Epoch 27 - Loss 0.014518776908516884\n",
      "Epoch 27 - Loss 0.003912332002073526\n",
      "Epoch 27 - Loss 0.1014510840177536\n",
      "Epoch 27 - Loss 0.004588896408677101\n",
      "Epoch 28 - Loss 0.04290667176246643\n",
      "Epoch 28 - Loss 0.03072846122086048\n",
      "Epoch 28 - Loss 0.012888447381556034\n",
      "Epoch 28 - Loss 0.003472904209047556\n",
      "Epoch 28 - Loss 0.09006306529045105\n",
      "Epoch 28 - Loss 0.00407395139336586\n",
      "Epoch 29 - Loss 0.038090091198682785\n",
      "Epoch 29 - Loss 0.027278829365968704\n",
      "Epoch 29 - Loss 0.011441321112215519\n",
      "Epoch 29 - Loss 0.0030830062460154295\n",
      "Epoch 29 - Loss 0.07995302975177765\n",
      "Epoch 29 - Loss 0.0036168929655104876\n",
      "Epoch 30 - Loss 0.03381390497088432\n",
      "Epoch 30 - Loss 0.024215685203671455\n",
      "Epoch 30 - Loss 0.010156898759305477\n",
      "Epoch 30 - Loss 0.0027369337622076273\n",
      "Epoch 30 - Loss 0.0709787905216217\n",
      "Epoch 30 - Loss 0.0032109699677675962\n",
      "Epoch 31 - Loss 0.03001810982823372\n",
      "Epoch 31 - Loss 0.02149750478565693\n",
      "Epoch 31 - Loss 0.009016536176204681\n",
      "Epoch 31 - Loss 0.0024296629708260298\n",
      "Epoch 31 - Loss 0.06301125884056091\n",
      "Epoch 31 - Loss 0.0028507495298981667\n",
      "Epoch 32 - Loss 0.02664813958108425\n",
      "Epoch 32 - Loss 0.01908363774418831\n",
      "Epoch 32 - Loss 0.008004182018339634\n",
      "Epoch 32 - Loss 0.002156773814931512\n",
      "Epoch 32 - Loss 0.05593801289796829\n",
      "Epoch 32 - Loss 0.002530534053221345\n",
      "Epoch 33 - Loss 0.02365723066031933\n",
      "Epoch 33 - Loss 0.016942208632826805\n",
      "Epoch 33 - Loss 0.0071060145273804665\n",
      "Epoch 33 - Loss 0.0019147968851029873\n",
      "Epoch 33 - Loss 0.04965822771191597\n",
      "Epoch 33 - Loss 0.0022461721673607826\n",
      "Epoch 34 - Loss 0.021001769229769707\n",
      "Epoch 34 - Loss 0.01504095271229744\n",
      "Epoch 34 - Loss 0.006308611016720533\n",
      "Epoch 34 - Loss 0.001699929591268301\n",
      "Epoch 34 - Loss 0.04408319666981697\n",
      "Epoch 34 - Loss 0.0019940552301704884\n",
      "Epoch 35 - Loss 0.0186439361423254\n",
      "Epoch 35 - Loss 0.01335214264690876\n",
      "Epoch 35 - Loss 0.005600250791758299\n",
      "Epoch 35 - Loss 0.0015090130036696792\n",
      "Epoch 35 - Loss 0.03913452476263046\n",
      "Epoch 35 - Loss 0.0017702386248856783\n",
      "Epoch 36 - Loss 0.016551116481423378\n",
      "Epoch 36 - Loss 0.01185330655425787\n",
      "Epoch 36 - Loss 0.00497151305899024\n",
      "Epoch 36 - Loss 0.0013397078728303313\n",
      "Epoch 36 - Loss 0.03474191576242447\n",
      "Epoch 36 - Loss 0.0015716658672317863\n",
      "Epoch 37 - Loss 0.014693044126033783\n",
      "Epoch 37 - Loss 0.010522279888391495\n",
      "Epoch 37 - Loss 0.00441333744674921\n",
      "Epoch 37 - Loss 0.0011892715701833367\n",
      "Epoch 37 - Loss 0.030842076987028122\n",
      "Epoch 37 - Loss 0.0013952851295471191\n",
      "Epoch 38 - Loss 0.013043627142906189\n",
      "Epoch 38 - Loss 0.009341062046587467\n",
      "Epoch 38 - Loss 0.003917821682989597\n",
      "Epoch 38 - Loss 0.0010557095520198345\n",
      "Epoch 38 - Loss 0.027379414066672325\n",
      "Epoch 38 - Loss 0.001238511293195188\n",
      "Epoch 39 - Loss 0.011579498648643494\n",
      "Epoch 39 - Loss 0.008292821235954762\n",
      "Epoch 39 - Loss 0.0034781889989972115\n",
      "Epoch 39 - Loss 0.0009372692438773811\n",
      "Epoch 39 - Loss 0.024306297302246094\n",
      "Epoch 39 - Loss 0.0010995363118126988\n",
      "Epoch 40 - Loss 0.010279619134962559\n",
      "Epoch 40 - Loss 0.00736183300614357\n",
      "Epoch 40 - Loss 0.00308777391910553\n",
      "Epoch 40 - Loss 0.0008319693733938038\n",
      "Epoch 40 - Loss 0.021577980369329453\n",
      "Epoch 40 - Loss 0.0009763240814208984\n",
      "Epoch 41 - Loss 0.009125486016273499\n",
      "Epoch 41 - Loss 0.00653489213436842\n",
      "Epoch 41 - Loss 0.00274082669056952\n",
      "Epoch 41 - Loss 0.000738529721274972\n",
      "Epoch 41 - Loss 0.019155900925397873\n",
      "Epoch 41 - Loss 0.0008667092770338058\n",
      "Epoch 42 - Loss 0.008101185783743858\n",
      "Epoch 42 - Loss 0.005801573395729065\n",
      "Epoch 42 - Loss 0.0024332369212061167\n",
      "Epoch 42 - Loss 0.0006557728629559278\n",
      "Epoch 42 - Loss 0.017005575820803642\n",
      "Epoch 42 - Loss 0.0007694283267483115\n",
      "Epoch 43 - Loss 0.007191687822341919\n",
      "Epoch 43 - Loss 0.005150070413947105\n",
      "Epoch 43 - Loss 0.0021600525360554457\n",
      "Epoch 43 - Loss 0.0005821584491059184\n",
      "Epoch 43 - Loss 0.015096677467226982\n",
      "Epoch 43 - Loss 0.0006830116035416722\n",
      "Epoch 44 - Loss 0.006384433247148991\n",
      "Epoch 44 - Loss 0.004572114907205105\n",
      "Epoch 44 - Loss 0.0019177192589268088\n",
      "Epoch 44 - Loss 0.0005168205825611949\n",
      "Epoch 44 - Loss 0.013402329757809639\n",
      "Epoch 44 - Loss 0.0006063350010663271\n",
      "Epoch 45 - Loss 0.0056678964756429195\n",
      "Epoch 45 - Loss 0.004058991093188524\n",
      "Epoch 45 - Loss 0.0017024469561874866\n",
      "Epoch 45 - Loss 0.0004588369047269225\n",
      "Epoch 45 - Loss 0.011897683143615723\n",
      "Epoch 45 - Loss 0.0005381974042393267\n",
      "Epoch 46 - Loss 0.0050316741690039635\n",
      "Epoch 46 - Loss 0.0036035417579114437\n",
      "Epoch 46 - Loss 0.0015115331625565886\n",
      "Epoch 46 - Loss 0.00040733773494139314\n",
      "Epoch 46 - Loss 0.010562230832874775\n",
      "Epoch 46 - Loss 0.00047769819502718747\n",
      "Epoch 47 - Loss 0.004466971382498741\n",
      "Epoch 47 - Loss 0.0031993077136576176\n",
      "Epoch 47 - Loss 0.0013419428141787648\n",
      "Epoch 47 - Loss 0.0003616183530539274\n",
      "Epoch 47 - Loss 0.009376119822263718\n",
      "Epoch 47 - Loss 0.0004240195848979056\n",
      "Epoch 48 - Loss 0.003965481650084257\n",
      "Epoch 48 - Loss 0.0028401173185557127\n",
      "Epoch 48 - Loss 0.0011913115158677101\n",
      "Epoch 48 - Loss 0.00032104155980050564\n",
      "Epoch 48 - Loss 0.008323506452143192\n",
      "Epoch 48 - Loss 0.00037649416481144726\n",
      "Epoch 49 - Loss 0.00352016044780612\n",
      "Epoch 49 - Loss 0.002520996145904064\n",
      "Epoch 49 - Loss 0.0010574455372989178\n",
      "Epoch 49 - Loss 0.00028493558056652546\n",
      "Epoch 49 - Loss 0.007389352191239595\n",
      "Epoch 49 - Loss 0.000334298936650157\n"
     ]
    }
   ],
   "source": [
    "#input = torch.randn(1)\n",
    "#out = net(input)\n",
    "\n",
    "#def criterion(out, label):\n",
    "#    return (label - out)**2\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.5)\n",
    "#optimizer = optim.Adam(net.parameters(), lr=0.005)\n",
    "\n",
    "for epoch in range(50):\n",
    "    for i, current in enumerate(data):\n",
    "        X1, X2, Y = current\n",
    "        X = torch.FloatTensor([[X1, X2]])\n",
    "        Y = torch.FloatTensor([[Y]])\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(X)\n",
    "        loss = criterion(Y, outputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(\"Epoch {} - Loss {}\" .format(epoch, loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "157966f3-6c5b-4449-8f61-e1b70e94f4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when x1 = 1.0 x2 = 2.1 , pred_y = tensor([[3.0559]], grad_fn=<AddmmBackward0>), y = tensor([[3.]])\n",
      "when x1 = 2.0 x2 = 3.5 , pred_y = tensor([[6.0542]], grad_fn=<AddmmBackward0>), y = tensor([[6.]])\n",
      "when x1 = 3.0 x2 = 3.0 , pred_y = tensor([[9.0571]], grad_fn=<AddmmBackward0>), y = tensor([[9.]])\n",
      "when x1 = 4.0 x2 = 2.1 , pred_y = tensor([[12.0610]], grad_fn=<AddmmBackward0>), y = tensor([[12.]])\n",
      "when x1 = 5.0 x2 = 7.2 , pred_y = tensor([[15.0504]], grad_fn=<AddmmBackward0>), y = tensor([[15.]])\n",
      "when x1 = 6.0 x2 = 10.1 , pred_y = tensor([[18.0451]], grad_fn=<AddmmBackward0>), y = tensor([[18.]])\n"
     ]
    }
   ],
   "source": [
    "for i, current in enumerate(data):\n",
    "        X1, X2, Y = current\n",
    "        X = torch.FloatTensor([[X1, X2]])\n",
    "        Y = torch.FloatTensor([[Y]])\n",
    "        out = net(X)\n",
    "        print(\"when x1 = {} x2 = {} , pred_y = {}, y = {}\" .format(X1, X2, out, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e302771e-005b-4977-beea-a3ada631ebfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
