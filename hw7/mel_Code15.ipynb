{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cosmetic-listing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import datasets\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# number of subprocesses to use for data loading\n",
    "num_workers = 0\n",
    "# how many samples per batch to load\n",
    "batch_size = 20\n",
    "\n",
    "# convert data to torch.FloatTensor\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_gpu else \"cpu\") \n",
    "\n",
    "PATH = \"save/trained_cnn_model.pt\"\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.1307), (0.3081))])\n",
    "\n",
    "\n",
    "# choose the training and test datasets\n",
    "train_data = datasets.MNIST(root='data', train=True, download=False,  transform=transform)\n",
    "test_data  = datasets.MNIST(root='data', train=False, download=False, transform=transform)\n",
    "\n",
    "# prepare data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "    num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
    "    num_workers=num_workers)\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "## Define the NN architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "model = Net().to(device)\n",
    "print(model)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fifteen-rhythm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.407418\n",
      "Epoch: 2 \tTraining Loss: 0.156157\n",
      "Epoch: 3 \tTraining Loss: 0.107206\n",
      "Epoch: 4 \tTraining Loss: 0.084939\n",
      "Epoch: 5 \tTraining Loss: 0.070567\n",
      "Epoch: 6 \tTraining Loss: 0.062605\n",
      "Epoch: 7 \tTraining Loss: 0.057260\n",
      "Epoch: 8 \tTraining Loss: 0.050419\n",
      "Epoch: 9 \tTraining Loss: 0.046523\n",
      "Epoch: 10 \tTraining Loss: 0.042122\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# number of epochs to train the model\n",
    "n_epochs = 10  \n",
    "# per epoch, all the training data set is used once\n",
    "model.train() # prep model for training\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # monitor training loss\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()*data.size(0) # as loss is tensor, .item() needed to get the value\n",
    "        \n",
    "    # print training statistics \n",
    "    # calculate average loss over an epoch\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch+1, train_loss))\n",
    "    \n",
    "# see following link for details of state_dict   \n",
    "# https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html\n",
    "torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': train_loss,\n",
    "            }, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "wireless-wagner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 9897/10000 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "train_loss = checkpoint['loss']\n",
    "\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)  \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "\n",
    "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "orange-termination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nparameters_to_prune = (\\n    (model.conv1, 'weight'),\\n    (model.conv2, 'weight'),\\n    (model.fc1, 'weight'),\\n    (model.fc2, 'weight'),\\n)\\n\\nprune.global_unstructured(\\n    parameters_to_prune,\\n    pruning_method=prune.L1Unstructured,\\n    amount=0.9,\\n)\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "\n",
    "## sparsity= 0.9, L1-norm, keep the maximum values\n",
    "prune.l1_unstructured(model.conv1, name='weight', amount=0.9)\n",
    "prune.l1_unstructured(model.conv2, name='weight', amount=0.9)\n",
    "prune.l1_unstructured(model.fc1, name='weight',   amount=0.9)\n",
    "prune.l1_unstructured(model.fc2, name='weight',   amount=0.9)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "parameters_to_prune = (\n",
    "    (model.conv1, 'weight'),\n",
    "    (model.conv2, 'weight'),\n",
    "    (model.fc1, 'weight'),\n",
    "    (model.fc2, 'weight'),\n",
    ")\n",
    "\n",
    "prune.global_unstructured(\n",
    "    parameters_to_prune,\n",
    "    pruning_method=prune.L1Unstructured,\n",
    "    amount=0.9,\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "swedish-trader",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('conv1.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.1767, -0.0641,  0.1383, -0.1277, -0.2425,  0.3985,  0.2801, -0.1825,\n",
       "           0.1816,  0.2958,  0.2951,  0.2997,  0.1704,  0.2194, -0.1753,  0.3444,\n",
       "           0.2839, -0.2019, -0.2521,  0.3300, -0.0445,  0.3421,  0.0340, -0.2177,\n",
       "          -0.1981,  0.1312,  0.3961,  0.2942, -0.2997,  0.0696, -0.2515, -0.0492],\n",
       "         device='cuda:0', requires_grad=True)),\n",
       " ('conv1.weight_orig',\n",
       "  Parameter containing:\n",
       "  tensor([[[[-0.1543, -0.3897, -0.2129],\n",
       "            [-0.1677, -0.0549, -0.4141],\n",
       "            [ 0.4592,  0.3294, -0.0461]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.3311, -0.0720, -0.1613],\n",
       "            [-0.2683, -0.3370,  0.0393],\n",
       "            [ 0.0042, -0.1206, -0.1392]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0348,  0.3495,  0.0787],\n",
       "            [ 0.1876, -0.2082,  0.2398],\n",
       "            [ 0.1089, -0.3401,  0.3614]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2217,  0.0509,  0.2880],\n",
       "            [-0.1665, -0.1999, -0.3127],\n",
       "            [ 0.0784,  0.0379,  0.0676]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0700, -0.2863,  0.0509],\n",
       "            [-0.2318, -0.0868, -0.1835],\n",
       "            [ 0.0735,  0.2243,  0.2917]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0571, -0.3867, -0.2179],\n",
       "            [-0.1670,  0.3274,  0.0442],\n",
       "            [ 0.5285,  0.5707,  0.2665]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2328, -0.4092,  0.1658],\n",
       "            [ 0.1244, -0.1309,  0.2966],\n",
       "            [-0.3802, -0.0626,  0.2041]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1673,  0.1645,  0.0460],\n",
       "            [-0.0482,  0.0922,  0.1061],\n",
       "            [ 0.0688,  0.4177, -0.0077]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1212, -0.1794,  0.1166],\n",
       "            [ 0.1326, -0.2536, -0.0891],\n",
       "            [ 0.1169,  0.2734, -0.2371]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.4131, -0.2216,  0.1187],\n",
       "            [ 0.4741,  0.0775,  0.3567],\n",
       "            [-0.0835, -0.2284,  0.2385]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1989, -0.4944, -0.5006],\n",
       "            [ 0.4440, -0.3190, -0.0106],\n",
       "            [ 0.5332,  0.4874,  0.1175]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1449,  0.2798,  0.4948],\n",
       "            [-0.3699,  0.2771,  0.6027],\n",
       "            [-0.3624, -0.1352,  0.3289]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.4064, -0.3264,  0.0779],\n",
       "            [-0.0334, -0.1863, -0.0809],\n",
       "            [ 0.5004,  0.2534,  0.3898]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1330, -0.0326, -0.4187],\n",
       "            [ 0.0010, -0.0787, -0.3117],\n",
       "            [-0.0733,  0.3226,  0.5014]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0271, -0.1926,  0.2217],\n",
       "            [ 0.0567, -0.1367, -0.1763],\n",
       "            [-0.0347, -0.2437,  0.1340]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1566,  0.1885, -0.0121],\n",
       "            [ 0.2409,  0.0529,  0.4368],\n",
       "            [ 0.4069,  0.6482,  0.4391]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1966, -0.0517,  0.1139],\n",
       "            [-0.2115,  0.3431,  0.0512],\n",
       "            [ 0.0377,  0.0519, -0.0703]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1572, -0.2879, -0.2871],\n",
       "            [-0.0069, -0.0080,  0.2746],\n",
       "            [-0.0957, -0.1843, -0.1494]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1589,  0.0552,  0.0261],\n",
       "            [-0.0474, -0.0661, -0.2844],\n",
       "            [-0.1068, -0.3146,  0.0380]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2038, -0.1314,  0.2450],\n",
       "            [-0.1824, -0.1428,  0.1908],\n",
       "            [-0.1788,  0.2551,  0.0604]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.4624, -0.3030,  0.3282],\n",
       "            [-0.3661,  0.3132,  0.2109],\n",
       "            [-0.0503,  0.1008,  0.3544]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.3350, -0.1647, -0.3061],\n",
       "            [-0.2449, -0.2537,  0.1070],\n",
       "            [ 0.3203,  0.3853,  0.3249]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2995, -0.3027, -0.1384],\n",
       "            [-0.2259,  0.3263, -0.0836],\n",
       "            [-0.1249,  0.0562,  0.2598]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.4358, -0.1472,  0.5310],\n",
       "            [-0.1308,  0.2759,  0.3706],\n",
       "            [ 0.3721,  0.4883,  0.2726]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.3120, -0.2800,  0.0614],\n",
       "            [-0.1299, -0.0315, -0.3308],\n",
       "            [-0.1461,  0.1331, -0.0989]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.3414,  0.1814,  0.3923],\n",
       "            [ 0.1661,  0.1503,  0.2813],\n",
       "            [-0.4651, -0.5139, -0.0695]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1040, -0.1259, -0.0439],\n",
       "            [-0.2118,  0.0642, -0.3269],\n",
       "            [ 0.0697,  0.1039,  0.3191]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.3559,  0.4852,  0.3628],\n",
       "            [-0.1346,  0.2398, -0.1632],\n",
       "            [-0.3111,  0.0335,  0.2641]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1736, -0.2411, -0.2168],\n",
       "            [ 0.1140, -0.1293,  0.0388],\n",
       "            [-0.2629,  0.2271, -0.0789]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2540, -0.3958, -0.3066],\n",
       "            [ 0.3227, -0.0252,  0.2828],\n",
       "            [-0.0064,  0.2945,  0.0806]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.3789, -0.2358,  0.1860],\n",
       "            [-0.2897, -0.1858,  0.3642],\n",
       "            [ 0.2807,  0.2554,  0.2720]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0457,  0.2276,  0.0661],\n",
       "            [ 0.1210,  0.2417, -0.3225],\n",
       "            [ 0.0104,  0.3508,  0.1263]]]], device='cuda:0', requires_grad=True)),\n",
       " ('conv2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0483, -0.0868, -0.0088, -0.0422, -0.0477, -0.0265, -0.0613, -0.0294,\n",
       "           0.0209,  0.0096, -0.0071, -0.0578, -0.0488,  0.0336, -0.0399, -0.0593,\n",
       "          -0.0135, -0.0285,  0.0422, -0.0535, -0.0409,  0.0229,  0.0283, -0.0277,\n",
       "          -0.0577, -0.0170,  0.0074, -0.0178,  0.0288,  0.0200,  0.0307, -0.0352,\n",
       "           0.0492, -0.0060,  0.0160,  0.0531, -0.0689,  0.0364, -0.0755,  0.0171,\n",
       "           0.0357,  0.0537, -0.0221, -0.0799, -0.0439, -0.0597, -0.0172,  0.0199,\n",
       "           0.0205, -0.0006, -0.0401, -0.0103, -0.0132, -0.0086, -0.0415,  0.0668,\n",
       "          -0.0475, -0.0156,  0.0341,  0.0003, -0.0405, -0.0009, -0.0101,  0.0529],\n",
       "         device='cuda:0', requires_grad=True)),\n",
       " ('conv2.weight_orig',\n",
       "  Parameter containing:\n",
       "  tensor([[[[ 0.0193,  0.0328, -0.0258],\n",
       "            [ 0.0346,  0.0750,  0.0169],\n",
       "            [ 0.0348,  0.0902,  0.0867]],\n",
       "  \n",
       "           [[ 0.0413, -0.0077,  0.0041],\n",
       "            [ 0.0311, -0.0483,  0.0297],\n",
       "            [ 0.0500,  0.0425,  0.0494]],\n",
       "  \n",
       "           [[-0.0630, -0.0386, -0.0456],\n",
       "            [ 0.0079, -0.0663, -0.0729],\n",
       "            [ 0.0286,  0.0365, -0.0698]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0016, -0.0388, -0.0402],\n",
       "            [-0.0096, -0.0270,  0.0109],\n",
       "            [ 0.0718, -0.0142,  0.0026]],\n",
       "  \n",
       "           [[ 0.0420,  0.0084, -0.0234],\n",
       "            [-0.0194,  0.0169,  0.0231],\n",
       "            [-0.0532, -0.0378, -0.0596]],\n",
       "  \n",
       "           [[-0.0833, -0.0696, -0.0173],\n",
       "            [-0.0369, -0.0430, -0.0435],\n",
       "            [ 0.0204,  0.0229, -0.0421]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0454,  0.0744,  0.0220],\n",
       "            [-0.0343, -0.0293, -0.0259],\n",
       "            [ 0.0191, -0.0131, -0.0432]],\n",
       "  \n",
       "           [[-0.0064,  0.0084, -0.0600],\n",
       "            [ 0.0491,  0.0213, -0.0195],\n",
       "            [-0.0172,  0.0353, -0.0557]],\n",
       "  \n",
       "           [[-0.0568, -0.0416, -0.0439],\n",
       "            [ 0.0380, -0.0166, -0.0109],\n",
       "            [-0.0313,  0.0428,  0.0674]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0022,  0.0417,  0.0100],\n",
       "            [-0.0453,  0.0871,  0.0922],\n",
       "            [ 0.0166, -0.0054,  0.0396]],\n",
       "  \n",
       "           [[-0.0272, -0.0644,  0.0539],\n",
       "            [-0.0468, -0.0742,  0.0044],\n",
       "            [-0.0845, -0.0615, -0.0197]],\n",
       "  \n",
       "           [[-0.0058,  0.0517,  0.0264],\n",
       "            [-0.0224, -0.0176,  0.0162],\n",
       "            [-0.0011,  0.0008,  0.0699]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0396, -0.0064, -0.0646],\n",
       "            [-0.0172, -0.0510,  0.0388],\n",
       "            [ 0.0442, -0.0055,  0.0525]],\n",
       "  \n",
       "           [[ 0.0096, -0.0228, -0.0559],\n",
       "            [ 0.0297,  0.0127,  0.0510],\n",
       "            [ 0.0234, -0.0500,  0.0209]],\n",
       "  \n",
       "           [[ 0.0364,  0.0123,  0.0367],\n",
       "            [-0.0187, -0.0055, -0.0654],\n",
       "            [ 0.0187, -0.0693, -0.0259]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[-0.0173, -0.0661, -0.0724],\n",
       "            [-0.0183, -0.0438,  0.0437],\n",
       "            [ 0.0353, -0.0007, -0.0401]],\n",
       "  \n",
       "           [[-0.0625,  0.0095,  0.0097],\n",
       "            [ 0.0234, -0.0339,  0.0116],\n",
       "            [ 0.0358,  0.0498, -0.0102]],\n",
       "  \n",
       "           [[ 0.0473,  0.0311,  0.0236],\n",
       "            [-0.0494,  0.0076, -0.0607],\n",
       "            [-0.0059, -0.0112, -0.0547]]],\n",
       "  \n",
       "  \n",
       "          ...,\n",
       "  \n",
       "  \n",
       "          [[[-0.0579, -0.0101, -0.0384],\n",
       "            [-0.0281, -0.0196, -0.0516],\n",
       "            [-0.0204, -0.0525, -0.0026]],\n",
       "  \n",
       "           [[ 0.0369, -0.0023,  0.0181],\n",
       "            [ 0.0356, -0.0415, -0.0353],\n",
       "            [ 0.0615, -0.0224, -0.0429]],\n",
       "  \n",
       "           [[-0.0264,  0.0536,  0.0352],\n",
       "            [-0.0317,  0.0134, -0.0177],\n",
       "            [-0.0695, -0.0306,  0.0688]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0421, -0.0532, -0.0776],\n",
       "            [ 0.0003, -0.0585, -0.0809],\n",
       "            [-0.0539, -0.0303, -0.0059]],\n",
       "  \n",
       "           [[-0.0267,  0.0111, -0.0397],\n",
       "            [ 0.0172,  0.0303, -0.0098],\n",
       "            [ 0.0413,  0.0767,  0.0339]],\n",
       "  \n",
       "           [[-0.0272,  0.0094,  0.0025],\n",
       "            [-0.0646, -0.0246,  0.0905],\n",
       "            [-0.0309, -0.0344,  0.0603]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0222, -0.0369, -0.0334],\n",
       "            [-0.0518, -0.0355, -0.0269],\n",
       "            [-0.0440, -0.0949,  0.0033]],\n",
       "  \n",
       "           [[ 0.0163,  0.0377, -0.0442],\n",
       "            [ 0.0413, -0.0041,  0.0133],\n",
       "            [-0.0330, -0.0005, -0.0196]],\n",
       "  \n",
       "           [[-0.0268, -0.0102,  0.0035],\n",
       "            [-0.0434, -0.0365, -0.0191],\n",
       "            [ 0.0487,  0.0237, -0.0713]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[-0.0739,  0.0025, -0.0784],\n",
       "            [-0.0518, -0.0928,  0.0042],\n",
       "            [-0.0481, -0.0402,  0.0351]],\n",
       "  \n",
       "           [[ 0.0402, -0.0661, -0.0351],\n",
       "            [ 0.0031, -0.0627, -0.0140],\n",
       "            [ 0.0780, -0.0453,  0.0199]],\n",
       "  \n",
       "           [[-0.0116,  0.0832,  0.0422],\n",
       "            [ 0.0540,  0.0060, -0.0116],\n",
       "            [-0.0258,  0.0729,  0.0379]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0289, -0.0331, -0.0438],\n",
       "            [-0.0396, -0.0030, -0.0125],\n",
       "            [-0.0784, -0.0362, -0.0666]],\n",
       "  \n",
       "           [[-0.0574,  0.0360, -0.0115],\n",
       "            [ 0.0353, -0.0161, -0.0013],\n",
       "            [-0.0528, -0.0499, -0.0381]],\n",
       "  \n",
       "           [[ 0.0190, -0.0131, -0.0101],\n",
       "            [ 0.0219, -0.0023,  0.0189],\n",
       "            [-0.0340, -0.0193,  0.0288]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[-0.0461,  0.0303, -0.0043],\n",
       "            [ 0.0953,  0.0415, -0.0067],\n",
       "            [-0.0462, -0.0121, -0.0720]],\n",
       "  \n",
       "           [[ 0.0369,  0.0505, -0.0158],\n",
       "            [ 0.0846,  0.0465, -0.0217],\n",
       "            [ 0.0377,  0.0571, -0.0385]],\n",
       "  \n",
       "           [[ 0.0163, -0.0409, -0.0117],\n",
       "            [-0.0326,  0.0376,  0.0193],\n",
       "            [-0.0169,  0.0513, -0.0794]]]], device='cuda:0', requires_grad=True)),\n",
       " ('fc1.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-1.5149e-03, -1.1456e-02, -9.5346e-03,  9.7326e-03, -1.6380e-03,\n",
       "           6.4331e-03,  3.2828e-03,  9.3965e-03, -1.2587e-02,  2.0281e-02,\n",
       "          -3.2000e-03, -3.1759e-03, -7.5996e-03, -6.1287e-03, -1.1691e-02,\n",
       "          -2.0992e-03,  9.6561e-04,  1.1976e-02, -1.0908e-02, -8.8923e-03,\n",
       "          -6.4008e-04, -1.0644e-02,  1.4378e-02, -1.2871e-02,  1.2019e-02,\n",
       "          -1.3376e-02,  7.1469e-03, -1.2859e-02, -5.6238e-03, -1.6663e-02,\n",
       "          -9.2359e-03, -3.8294e-03,  1.4151e-02,  1.3149e-02,  8.6282e-03,\n",
       "          -1.0370e-02,  3.6235e-04,  8.4251e-03,  1.4788e-02,  4.4474e-03,\n",
       "          -9.7628e-03,  4.6785e-03,  1.2047e-02, -3.4713e-03, -9.8066e-04,\n",
       "           7.7471e-04,  1.0369e-02,  5.0626e-03, -5.7299e-03,  1.0790e-02,\n",
       "           3.0534e-03,  1.5452e-02,  9.7787e-03,  5.9459e-03, -1.4007e-02,\n",
       "           1.3933e-02, -4.1810e-03,  2.2912e-03, -8.7813e-03, -5.1055e-03,\n",
       "          -2.6061e-03,  8.6241e-04, -5.7320e-03,  1.5868e-02,  1.5464e-02,\n",
       "          -7.7428e-04, -1.0562e-02,  4.0714e-03, -5.6862e-05, -7.6385e-03,\n",
       "          -8.0726e-03, -1.2447e-02,  2.6769e-03,  7.2347e-04, -7.7773e-03,\n",
       "           4.7627e-04,  5.2250e-03, -8.3062e-03,  1.4182e-02, -1.1755e-02,\n",
       "          -8.6177e-03,  6.8876e-03,  2.2980e-03, -9.1276e-03,  6.0428e-03,\n",
       "           7.4230e-03,  3.0798e-03,  1.3309e-02,  1.2503e-02, -1.1032e-02,\n",
       "           1.7382e-02,  8.9469e-05,  2.4442e-04, -1.2333e-02, -5.9381e-03,\n",
       "           1.9206e-03,  5.6354e-03, -9.3704e-03, -1.1313e-02,  8.9899e-03,\n",
       "          -4.7742e-03,  1.7915e-02, -2.6558e-04,  8.8604e-03,  8.8090e-03,\n",
       "          -5.4309e-03, -3.9378e-03, -6.8027e-03, -4.7862e-03, -9.8263e-03,\n",
       "          -1.0980e-03,  1.8966e-02,  2.5620e-03, -1.0374e-03, -5.6057e-03,\n",
       "          -1.2349e-02,  2.1830e-03, -1.3756e-03, -2.3640e-03,  7.0325e-03,\n",
       "          -1.3198e-02, -2.3593e-03, -2.9655e-03, -4.2704e-03,  1.4404e-03,\n",
       "          -1.1180e-02,  6.3126e-03, -1.8963e-03], device='cuda:0',\n",
       "         requires_grad=True)),\n",
       " ('fc1.weight_orig',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0067, -0.0084, -0.0026,  ..., -0.0146, -0.0006, -0.0019],\n",
       "          [ 0.0050, -0.0003,  0.0029,  ...,  0.0101,  0.0130, -0.0009],\n",
       "          [-0.0031,  0.0044, -0.0048,  ...,  0.0072,  0.0032, -0.0055],\n",
       "          ...,\n",
       "          [-0.0098, -0.0075, -0.0079,  ..., -0.0142, -0.0101, -0.0072],\n",
       "          [ 0.0043,  0.0024,  0.0003,  ...,  0.0089,  0.0022,  0.0011],\n",
       "          [ 0.0010,  0.0128,  0.0087,  ...,  0.0019,  0.0031,  0.0009]],\n",
       "         device='cuda:0', requires_grad=True)),\n",
       " ('fc2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0013,  0.0441,  0.0156, -0.0450, -0.0165, -0.1223, -0.1160,  0.0089,\n",
       "           0.1034, -0.0990], device='cuda:0', requires_grad=True)),\n",
       " ('fc2.weight_orig',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0141,  0.1028,  0.1615,  ..., -0.0373, -0.1141,  0.1354],\n",
       "          [-0.1198, -0.1974,  0.1057,  ...,  0.0593, -0.0899, -0.1082],\n",
       "          [ 0.1593, -0.1383,  0.0265,  ..., -0.0656, -0.1395, -0.1942],\n",
       "          ...,\n",
       "          [-0.1144, -0.1455,  0.0688,  ...,  0.1393,  0.1239,  0.1374],\n",
       "          [ 0.0298,  0.1173,  0.0674,  ...,  0.1382, -0.1974, -0.0380],\n",
       "          [-0.1287,  0.1032,  0.1291,  ..., -0.1248,  0.1209, -0.1179]],\n",
       "         device='cuda:0', requires_grad=True))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.named_parameters())   ## print original weights and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "continued-sense",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.0000, -0.0000, -0.0000],\n",
       "          [-0.0000, -0.0000, -0.4141],\n",
       "          [ 0.4592,  0.0000, -0.0000]]],\n",
       "\n",
       "\n",
       "        [[[-0.0000, -0.0000, -0.0000],\n",
       "          [-0.0000, -0.0000,  0.0000],\n",
       "          [ 0.0000, -0.0000, -0.0000]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000, -0.0000,  0.0000],\n",
       "          [ 0.0000, -0.0000,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[-0.0000,  0.0000,  0.0000],\n",
       "          [-0.0000, -0.0000, -0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[-0.0000, -0.0000,  0.0000],\n",
       "          [-0.0000, -0.0000, -0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000, -0.0000, -0.0000],\n",
       "          [-0.0000,  0.0000,  0.0000],\n",
       "          [ 0.5285,  0.5707,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[-0.0000, -0.4092,  0.0000],\n",
       "          [ 0.0000, -0.0000,  0.0000],\n",
       "          [-0.0000, -0.0000,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[-0.0000,  0.0000,  0.0000],\n",
       "          [-0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.4177, -0.0000]]],\n",
       "\n",
       "\n",
       "        [[[-0.0000, -0.0000,  0.0000],\n",
       "          [ 0.0000, -0.0000, -0.0000],\n",
       "          [ 0.0000,  0.0000, -0.0000]]],\n",
       "\n",
       "\n",
       "        [[[ 0.4131, -0.0000,  0.0000],\n",
       "          [ 0.4741,  0.0000,  0.0000],\n",
       "          [-0.0000, -0.0000,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000, -0.4944, -0.5006],\n",
       "          [ 0.4440, -0.0000, -0.0000],\n",
       "          [ 0.5332,  0.4874,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000,  0.0000,  0.4948],\n",
       "          [-0.0000,  0.0000,  0.6027],\n",
       "          [-0.0000, -0.0000,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[-0.0000, -0.0000,  0.0000],\n",
       "          [-0.0000, -0.0000, -0.0000],\n",
       "          [ 0.5004,  0.0000,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000, -0.0000, -0.4187],\n",
       "          [ 0.0000, -0.0000, -0.0000],\n",
       "          [-0.0000,  0.0000,  0.5014]]],\n",
       "\n",
       "\n",
       "        [[[-0.0000, -0.0000,  0.0000],\n",
       "          [ 0.0000, -0.0000, -0.0000],\n",
       "          [-0.0000, -0.0000,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[-0.0000,  0.0000, -0.0000],\n",
       "          [ 0.0000,  0.0000,  0.4368],\n",
       "          [ 0.4069,  0.6482,  0.4391]]],\n",
       "\n",
       "\n",
       "        [[[-0.0000, -0.0000,  0.0000],\n",
       "          [-0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000, -0.0000]]],\n",
       "\n",
       "\n",
       "        [[[-0.0000, -0.0000, -0.0000],\n",
       "          [-0.0000, -0.0000,  0.0000],\n",
       "          [-0.0000, -0.0000, -0.0000]]],\n",
       "\n",
       "\n",
       "        [[[-0.0000,  0.0000,  0.0000],\n",
       "          [-0.0000, -0.0000, -0.0000],\n",
       "          [-0.0000, -0.0000,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[-0.0000, -0.0000,  0.0000],\n",
       "          [-0.0000, -0.0000,  0.0000],\n",
       "          [-0.0000,  0.0000,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[-0.4624, -0.0000,  0.0000],\n",
       "          [-0.0000,  0.0000,  0.0000],\n",
       "          [-0.0000,  0.0000,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[-0.0000, -0.0000, -0.0000],\n",
       "          [-0.0000, -0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[-0.0000, -0.0000, -0.0000],\n",
       "          [-0.0000,  0.0000, -0.0000],\n",
       "          [-0.0000,  0.0000,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[-0.4358, -0.0000,  0.5310],\n",
       "          [-0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.4883,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[-0.0000, -0.0000,  0.0000],\n",
       "          [-0.0000, -0.0000, -0.0000],\n",
       "          [-0.0000,  0.0000, -0.0000]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [-0.4651, -0.5139, -0.0000]]],\n",
       "\n",
       "\n",
       "        [[[-0.0000, -0.0000, -0.0000],\n",
       "          [-0.0000,  0.0000, -0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000,  0.4852,  0.0000],\n",
       "          [-0.0000,  0.0000, -0.0000],\n",
       "          [-0.0000,  0.0000,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[-0.0000, -0.0000, -0.0000],\n",
       "          [ 0.0000, -0.0000,  0.0000],\n",
       "          [-0.0000,  0.0000, -0.0000]]],\n",
       "\n",
       "\n",
       "        [[[-0.0000, -0.0000, -0.0000],\n",
       "          [ 0.0000, -0.0000,  0.0000],\n",
       "          [-0.0000,  0.0000,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[-0.0000, -0.0000,  0.0000],\n",
       "          [-0.0000, -0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000, -0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0',\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv1.weight  ## weights after pruning   weight = weight_orig*weight_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "resistant-investing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0.],\n",
       "          [0., 0., 1.],\n",
       "          [1., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [1., 1., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 1., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 1., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[1., 0., 0.],\n",
       "          [1., 0., 0.],\n",
       "          [0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 1., 1.],\n",
       "          [1., 0., 0.],\n",
       "          [1., 1., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 1.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [1., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 1.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 1.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.],\n",
       "          [0., 0., 1.],\n",
       "          [1., 1., 1.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[1., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[1., 0., 1.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 1., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [1., 1., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 1., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]]]], device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv1.weight_mask  ## pruning position=0   non-pruning position = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "approved-dakota",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[-0.1543, -0.3897, -0.2129],\n",
      "          [-0.1677, -0.0549, -0.4141],\n",
      "          [ 0.4592,  0.3294, -0.0461]]],\n",
      "\n",
      "\n",
      "        [[[-0.3311, -0.0720, -0.1613],\n",
      "          [-0.2683, -0.3370,  0.0393],\n",
      "          [ 0.0042, -0.1206, -0.1392]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0348,  0.3495,  0.0787],\n",
      "          [ 0.1876, -0.2082,  0.2398],\n",
      "          [ 0.1089, -0.3401,  0.3614]]],\n",
      "\n",
      "\n",
      "        [[[-0.2217,  0.0509,  0.2880],\n",
      "          [-0.1665, -0.1999, -0.3127],\n",
      "          [ 0.0784,  0.0379,  0.0676]]],\n",
      "\n",
      "\n",
      "        [[[-0.0700, -0.2863,  0.0509],\n",
      "          [-0.2318, -0.0868, -0.1835],\n",
      "          [ 0.0735,  0.2243,  0.2917]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0571, -0.3867, -0.2179],\n",
      "          [-0.1670,  0.3274,  0.0442],\n",
      "          [ 0.5285,  0.5707,  0.2665]]],\n",
      "\n",
      "\n",
      "        [[[-0.2328, -0.4092,  0.1658],\n",
      "          [ 0.1244, -0.1309,  0.2966],\n",
      "          [-0.3802, -0.0626,  0.2041]]],\n",
      "\n",
      "\n",
      "        [[[-0.1673,  0.1645,  0.0460],\n",
      "          [-0.0482,  0.0922,  0.1061],\n",
      "          [ 0.0688,  0.4177, -0.0077]]],\n",
      "\n",
      "\n",
      "        [[[-0.1212, -0.1794,  0.1166],\n",
      "          [ 0.1326, -0.2536, -0.0891],\n",
      "          [ 0.1169,  0.2734, -0.2371]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4131, -0.2216,  0.1187],\n",
      "          [ 0.4741,  0.0775,  0.3567],\n",
      "          [-0.0835, -0.2284,  0.2385]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1989, -0.4944, -0.5006],\n",
      "          [ 0.4440, -0.3190, -0.0106],\n",
      "          [ 0.5332,  0.4874,  0.1175]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1449,  0.2798,  0.4948],\n",
      "          [-0.3699,  0.2771,  0.6027],\n",
      "          [-0.3624, -0.1352,  0.3289]]],\n",
      "\n",
      "\n",
      "        [[[-0.4064, -0.3264,  0.0779],\n",
      "          [-0.0334, -0.1863, -0.0809],\n",
      "          [ 0.5004,  0.2534,  0.3898]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1330, -0.0326, -0.4187],\n",
      "          [ 0.0010, -0.0787, -0.3117],\n",
      "          [-0.0733,  0.3226,  0.5014]]],\n",
      "\n",
      "\n",
      "        [[[-0.0271, -0.1926,  0.2217],\n",
      "          [ 0.0567, -0.1367, -0.1763],\n",
      "          [-0.0347, -0.2437,  0.1340]]],\n",
      "\n",
      "\n",
      "        [[[-0.1566,  0.1885, -0.0121],\n",
      "          [ 0.2409,  0.0529,  0.4368],\n",
      "          [ 0.4069,  0.6482,  0.4391]]],\n",
      "\n",
      "\n",
      "        [[[-0.1966, -0.0517,  0.1139],\n",
      "          [-0.2115,  0.3431,  0.0512],\n",
      "          [ 0.0377,  0.0519, -0.0703]]],\n",
      "\n",
      "\n",
      "        [[[-0.1572, -0.2879, -0.2871],\n",
      "          [-0.0069, -0.0080,  0.2746],\n",
      "          [-0.0957, -0.1843, -0.1494]]],\n",
      "\n",
      "\n",
      "        [[[-0.1589,  0.0552,  0.0261],\n",
      "          [-0.0474, -0.0661, -0.2844],\n",
      "          [-0.1068, -0.3146,  0.0380]]],\n",
      "\n",
      "\n",
      "        [[[-0.2038, -0.1314,  0.2450],\n",
      "          [-0.1824, -0.1428,  0.1908],\n",
      "          [-0.1788,  0.2551,  0.0604]]],\n",
      "\n",
      "\n",
      "        [[[-0.4624, -0.3030,  0.3282],\n",
      "          [-0.3661,  0.3132,  0.2109],\n",
      "          [-0.0503,  0.1008,  0.3544]]],\n",
      "\n",
      "\n",
      "        [[[-0.3350, -0.1647, -0.3061],\n",
      "          [-0.2449, -0.2537,  0.1070],\n",
      "          [ 0.3203,  0.3853,  0.3249]]],\n",
      "\n",
      "\n",
      "        [[[-0.2995, -0.3027, -0.1384],\n",
      "          [-0.2259,  0.3263, -0.0836],\n",
      "          [-0.1249,  0.0562,  0.2598]]],\n",
      "\n",
      "\n",
      "        [[[-0.4358, -0.1472,  0.5310],\n",
      "          [-0.1308,  0.2759,  0.3706],\n",
      "          [ 0.3721,  0.4883,  0.2726]]],\n",
      "\n",
      "\n",
      "        [[[-0.3120, -0.2800,  0.0614],\n",
      "          [-0.1299, -0.0315, -0.3308],\n",
      "          [-0.1461,  0.1331, -0.0989]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3414,  0.1814,  0.3923],\n",
      "          [ 0.1661,  0.1503,  0.2813],\n",
      "          [-0.4651, -0.5139, -0.0695]]],\n",
      "\n",
      "\n",
      "        [[[-0.1040, -0.1259, -0.0439],\n",
      "          [-0.2118,  0.0642, -0.3269],\n",
      "          [ 0.0697,  0.1039,  0.3191]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3559,  0.4852,  0.3628],\n",
      "          [-0.1346,  0.2398, -0.1632],\n",
      "          [-0.3111,  0.0335,  0.2641]]],\n",
      "\n",
      "\n",
      "        [[[-0.1736, -0.2411, -0.2168],\n",
      "          [ 0.1140, -0.1293,  0.0388],\n",
      "          [-0.2629,  0.2271, -0.0789]]],\n",
      "\n",
      "\n",
      "        [[[-0.2540, -0.3958, -0.3066],\n",
      "          [ 0.3227, -0.0252,  0.2828],\n",
      "          [-0.0064,  0.2945,  0.0806]]],\n",
      "\n",
      "\n",
      "        [[[-0.3789, -0.2358,  0.1860],\n",
      "          [-0.2897, -0.1858,  0.3642],\n",
      "          [ 0.2807,  0.2554,  0.2720]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0457,  0.2276,  0.0661],\n",
      "          [ 0.1210,  0.2417, -0.3225],\n",
      "          [ 0.0104,  0.3508,  0.1263]]]], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.conv1.weight_orig) ## original weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "binding-sunglasses",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv1:  tensor(0.8993, device='cuda:0')\n",
      "Conv2:  tensor(0.9000, device='cuda:0')\n",
      "FC1:    tensor(0.9000, device='cuda:0')\n",
      "FC2:    tensor(0.9000, device='cuda:0')\n",
      "total:  tensor(0.9000, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "mask1 = model.conv1.weight_mask\n",
    "mask2 = model.conv2.weight_mask\n",
    "mask3 = model.fc1.weight_mask\n",
    "mask4 = model.fc2.weight_mask\n",
    "sparsity_mask1 = (mask1 == 0).sum() / mask1.nelement()  ## calculate percentage of zeros\n",
    "sparsity_mask2 = (mask2 == 0).sum() / mask2.nelement()\n",
    "sparsity_mask3 = (mask3 == 0).sum() / mask3.nelement()\n",
    "sparsity_mask4 = (mask4 == 0).sum() / mask4.nelement()\n",
    "print(\"Conv1: \", sparsity_mask1)\n",
    "print(\"Conv2: \", sparsity_mask2)\n",
    "print(\"FC1:   \", sparsity_mask3)\n",
    "print(\"FC2:   \", sparsity_mask4)\n",
    "\n",
    "total_zeros = (mask1 == 0).sum() + (mask2 == 0).sum() + (mask3 == 0).sum() + (mask4 == 0).sum()\n",
    "total_elements = mask1.nelement() + mask2.nelement() + mask3.nelement() + mask4.nelement()\n",
    "\n",
    "print(\"total: \", total_zeros / total_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "international-financing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 4942/10000 (49%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)  \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "\n",
    "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fiscal-breed",
   "metadata": {},
   "outputs": [],
   "source": [
    "### This cell removes the weight_orig and weight_mask, but only store the pruned weight\n",
    "### Note that if you want to fine-tune with the next cell, you should not run this cell\n",
    "### If you run this cell and finetune, the pruned weight will be updated again.\n",
    "prune.remove(model.conv1, 'weight')\n",
    "prune.remove(model.conv2, 'weight')\n",
    "prune.remove(model.fc1, 'weight')\n",
    "prune.remove(model.fc2, 'weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "prostate-question",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.337096\n",
      "Epoch: 2 \tTraining Loss: 0.195101\n",
      "Epoch: 3 \tTraining Loss: 0.164772\n",
      "Epoch: 4 \tTraining Loss: 0.145192\n",
      "Epoch: 5 \tTraining Loss: 0.132416\n",
      "Epoch: 6 \tTraining Loss: 0.126836\n",
      "Epoch: 7 \tTraining Loss: 0.115685\n",
      "Epoch: 8 \tTraining Loss: 0.111675\n",
      "Epoch: 9 \tTraining Loss: 0.105740\n",
      "Epoch: 10 \tTraining Loss: 0.100351\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# number of epochs to train the model\n",
    "n_epochs = 10  \n",
    "# per epoch, all the training data set is used once\n",
    "model.train() # prep model for training\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # monitor training loss\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()*data.size(0) # as loss is tensor, .item() needed to get the value\n",
    "        \n",
    "    # print training statistics \n",
    "    # calculate average loss over an epoch\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch+1, train_loss))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "classified-omaha",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see following link for details of state_dict   \n",
    "# https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html\n",
    "PATH_prune = \"save/trained_cnn_model_pruned.pt\"\n",
    "\n",
    "torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': train_loss,\n",
    "            }, PATH_prune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-olympus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After above finetuning, run the 7th cell to check the sparsity.\n",
    "# Then, check the accuracy by running the 8th cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "charged-chrome",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 9860/10000 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Now, after running the first cell, let's try to load the stored model.\n",
    "## It won't work because the named_parameters has been changed.\n",
    "## Thus, run 4th cell to make a pruned model.\n",
    "## Then, run this cell.\n",
    "\n",
    "PATH_prune = \"save/trained_cnn_model_pruned.pt\"\n",
    "checkpoint = torch.load(PATH_prune)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "train_loss = checkpoint['loss']\n",
    "\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)  \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "\n",
    "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-consortium",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
